{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr \n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to\n",
      "[nltk_data]     C:\\Users\\Anjali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package udhr is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('udhr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = udhr.raw('English-Latin1')\n",
    "french = udhr.raw('French_Francais-Latin1')\n",
    "italian = udhr.raw('Italian_Italiano-Latin1')\n",
    "spanish = udhr.raw('Spanish_Espanol-Latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Training Dataset and Developement dataset for English,French, Italian, Spanish\n",
    "english_train, english_dev = english[0:1000], english[1000:1100]\n",
    "french_train, french_dev = french[0:1000], french[1000:1100]\n",
    "italian_train, italian_dev = italian[0:1000], italian[1000:1100]\n",
    "spanish_train, spanish_dev = spanish[0:1000], spanish[1000:1100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Test Dataset for English,French, Italian, Spanish\n",
    "english_test = udhr.words('English-Latin1')[0:1000]\n",
    "french_test = udhr.words('French_Francais-Latin1')[0:1000]\n",
    "italian_test = udhr.words('Italian_Italiano-Latin1')[0:1000]\n",
    "spanish_test = udhr.words('Spanish_Espanol-Latin1')[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the Corpus\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['universal', 'declaration', 'of', 'human', 'rights', 'preamble', 'whereas', 'recognition', 'of', 'the', 'inherent', 'dignity', 'and', 'of', 'the', 'equal', 'and', 'inalienable', 'rights', 'of', 'all', 'members', 'of', 'the', 'human', 'family', 'is', 'the', 'foundation', 'of', 'freedom', 'justice', 'and', 'peace', 'in', 'the', 'world', 'whereas', 'disregard', 'and', 'contempt', 'for', 'human', 'rights', 'have', 'resulted', 'in', 'barbarous', 'acts', 'which', 'have', 'outraged', 'the', 'conscience', 'of', 'mankind', 'and', 'the', 'advent', 'of', 'a', 'world', 'in', 'which', 'human', 'beings', 'shall', 'enjoy', 'freedom', 'of', 'speech', 'and', 'belief', 'and', 'freedom', 'from', 'fear', 'and', 'want', 'has', 'been', 'proclaimed', 'as', 'the', 'highest', 'aspiration', 'of', 'the', 'common', 'people', 'whereas', 'it', 'is', 'essential', 'if', 'man', 'is', 'not', 'to', 'be']\n"
     ]
    }
   ],
   "source": [
    "# Processing English Corpus and lower case all words\n",
    "\n",
    "english_train_words = english_train.split()\n",
    "english_train_words = [word.lower() for word in english_train_words]\n",
    "# remove punctuation from each word\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "english_train = [w.translate(table) for w in english_train_words]\n",
    "english_test = [token.lower() for token in english_test]\n",
    "print(english_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['déclaration', 'universelle', 'des', 'droits', 'de', 'lhomme', 'préambule', 'considérant', 'que', 'la', 'reconnaissance', 'de', 'la', 'dignité', 'inhérente', 'à', 'tous', 'les', 'membres', 'de', 'la', 'famille', 'humaine', 'et', 'de', 'leurs', 'droits', 'égaux', 'et', 'inaliénables', 'constitue', 'le', 'fondement', 'de', 'la', 'liberté', 'de', 'la', 'justice', 'et', 'de', 'la', 'paix', 'dans', 'le', 'monde', 'considérant', 'que', 'la', 'méconnaissance', 'et', 'le', 'mépris', 'des', 'droits', 'de', 'lhomme', 'ont', 'conduit', 'à', 'des', 'actes', 'de', 'barbarie', 'qui', 'révoltent', 'la', 'conscience', 'de', 'lhumanité', 'et', 'que', 'lavènement', 'dun', 'monde', 'où', 'les', 'êtres', 'humains', 'seront', 'libres', 'de', 'parler', 'et', 'de', 'croire', 'libérés', 'de', 'la', 'terreur', 'et', 'de', 'la', 'misère', 'a', 'été', 'proclamé', 'comme', 'la', 'plus']\n"
     ]
    }
   ],
   "source": [
    "# Processing French Corpus and lower case all words\n",
    "\n",
    "french_train_words = french_train.split()\n",
    "french_train_words = [word.lower() for word in french_train_words]\n",
    "# remove punctuation from each word\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "french_train = [w.translate(table) for w in french_train_words]\n",
    "french_test = [token.lower() for token in french_test]\n",
    "print(french_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dichiarazione', 'universale', 'dei', 'diritti', 'umani', 'preambolo', 'considerato', 'che', 'il', 'riconoscimento', 'della', 'dignità', 'inerente', 'a', 'tutti', 'i', 'membri', 'della', 'famiglia', 'umana', 'e', 'dei', 'loro', 'diritti', 'uguali', 'ed', 'inalienabili', 'costituisce', 'il', 'fondamento', 'della', 'libertà', 'della', 'giustizia', 'e', 'della', 'pace', 'nel', 'mondo', 'considerato', 'che', 'il', 'disconoscimento', 'e', 'il', 'disprezzo', 'dei', 'diritti', 'umani', 'hanno', 'portato', 'ad', 'atti', 'di', 'barbarie', 'che', 'offendono', 'la', 'coscienza', 'dellumanità', 'e', 'che', 'lavvento', 'di', 'un', 'mondo', 'in', 'cui', 'gli', 'esseri', 'umani', 'godano', 'della', 'libertà', 'di', 'parola', 'e', 'di', 'credo', 'e', 'della', 'libertà', 'dal', 'timore', 'e', 'dal', 'bisogno', 'è', 'stato', 'proclamato', 'come', 'la', 'più', 'alta', 'aspirazione', 'delluomo', 'considerato', 'che', 'è', 'indispensabile']\n"
     ]
    }
   ],
   "source": [
    "# Processing Italian Corpus and lower case all words\n",
    "\n",
    "italian_train_words = italian_train.split()\n",
    "italian_train_words = [word.lower() for word in italian_train_words]\n",
    "# remove punctuation from each word\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "italian_train = [w.translate(table) for w in italian_train_words]\n",
    "italian_test = [token.lower() for token in italian_test]\n",
    "print(italian_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['declaración', 'universal', 'de', 'derechos', 'humanos', 'adoptada', 'y', 'proclamada', 'por', 'la', 'asamblea', 'general', 'en', 'su', 'resolución', '217', 'a', 'iii', 'de', '10', 'de', 'diciembre', 'de', '1948', 'preámbulo', 'considerando', 'que', 'la', 'libertad', 'la', 'justicia', 'y', 'la', 'paz', 'en', 'el', 'mundo', 'tienen', 'por', 'base', 'el', 'reconocimiento', 'de', 'la', 'dignidad', 'intrínseca', 'y', 'de', 'los', 'derechos', 'iguales', 'e', 'inalienables', 'de', 'todos', 'los', 'miembros', 'de', 'la', 'familia', 'humana', 'considerando', 'que', 'el', 'desconocimiento', 'y', 'el', 'menosprecio', 'de', 'los', 'derechos', 'humanos', 'han', 'originado', 'actos', 'de', 'barbarie', 'ultrajantes', 'para', 'la', 'conciencia', 'de', 'la', 'humanidad', 'y', 'que', 'se', 'ha', 'proclamado', 'como', 'la', 'aspiración', 'más', 'elevada', 'del', 'hombre', 'el', 'advenimiento', 'de', 'un']\n"
     ]
    }
   ],
   "source": [
    "# Processing spanish Corpus and lower case all words\n",
    "\n",
    "spanish_train_words = spanish_train.split()\n",
    "spanish_train_words = [word.lower() for word in spanish_train_words]\n",
    "# remove punctuation from each word\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "spanish_train = [w.translate(table) for w in spanish_train_words]\n",
    "spanish_test = [token.lower() for token in spanish_test]\n",
    "print(spanish_train[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating models for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Unigram model\n",
      "<FreqDist with 89 samples and 167 outcomes>\n",
      "English bigram model\n",
      "<FreqDist with 151 samples and 166 outcomes>\n",
      "English trigram model\n",
      "<FreqDist with 162 samples and 165 outcomes>\n"
     ]
    }
   ],
   "source": [
    "# unigram Models\n",
    "print(\"English Unigram model\")\n",
    "fdist_unigram_english=nltk.FreqDist(list(nltk.ngrams(english_train,1)))\n",
    "print(fdist_unigram_english)\n",
    "\n",
    "#bigram Model\n",
    "print(\"English bigram model\")\n",
    "fdist_bigram_english=nltk.FreqDist(list(nltk.bigrams(english_train)))\n",
    "print(fdist_bigram_english)\n",
    "\n",
    "#trigram model\n",
    "print(\"English trigram model\")\n",
    "fdist_trigram_english=nltk.FreqDist(list(nltk.trigrams(english_train)))\n",
    "print(fdist_trigram_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating models for French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Unigram model\n",
      "<FreqDist with 91 samples and 164 outcomes>\n",
      "French bigram model\n",
      "<FreqDist with 142 samples and 163 outcomes>\n",
      "French trigram model\n",
      "<FreqDist with 155 samples and 162 outcomes>\n"
     ]
    }
   ],
   "source": [
    "# unigram Models\n",
    "print(\"French Unigram model\")\n",
    "fdist_unigram_french=nltk.FreqDist(list(nltk.ngrams(french_train,1)))\n",
    "print(fdist_unigram_french)\n",
    "\n",
    "#bigram Model\n",
    "print(\"French bigram model\")\n",
    "fdist_bigram_french=nltk.FreqDist(list(nltk.bigrams(french_train)))\n",
    "print(fdist_bigram_french)\n",
    "\n",
    "#trigram model\n",
    "print(\"French trigram model\")\n",
    "fdist_trigram_french=nltk.FreqDist(list(nltk.trigrams(french_train)))\n",
    "print(fdist_trigram_french)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating models for Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italian Unigram model\n",
      "<FreqDist with 98 samples and 153 outcomes>\n",
      "italian bigram model\n",
      "<FreqDist with 138 samples and 152 outcomes>\n",
      "italian trigram model\n",
      "<FreqDist with 147 samples and 151 outcomes>\n"
     ]
    }
   ],
   "source": [
    "# unigram Models\n",
    "print(\"italian Unigram model\")\n",
    "fdist_unigram_italian=nltk.FreqDist(list(nltk.ngrams(italian_train,1)))\n",
    "print(fdist_unigram_italian)\n",
    "\n",
    "#bigram Model\n",
    "print(\"italian bigram model\")\n",
    "fdist_bigram_italian=nltk.FreqDist(list(nltk.bigrams(italian_train)))\n",
    "print(fdist_bigram_italian)\n",
    "\n",
    "#trigram model\n",
    "print(\"italian trigram model\")\n",
    "fdist_trigram_italian=nltk.FreqDist(list(nltk.trigrams(italian_train)))\n",
    "print(fdist_trigram_italian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating models for spanish language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish Unigram model\n",
      "<FreqDist with 89 samples and 166 outcomes>\n",
      "spanish bigram model\n",
      "<FreqDist with 145 samples and 165 outcomes>\n",
      "spanish trigram model\n",
      "<FreqDist with 159 samples and 164 outcomes>\n"
     ]
    }
   ],
   "source": [
    "# unigram Models\n",
    "print(\"spanish Unigram model\")\n",
    "fdist_unigram_spanish=nltk.FreqDist(list(nltk.ngrams(spanish_train,1)))\n",
    "print(fdist_unigram_spanish)\n",
    "\n",
    "#bigram Model\n",
    "print(\"spanish bigram model\")\n",
    "fdist_bigram_spanish=nltk.FreqDist(list(nltk.bigrams(spanish_train)))\n",
    "print(fdist_bigram_spanish)\n",
    "\n",
    "#trigram model\n",
    "print(\"spanish trigram model\")\n",
    "fdist_trigram_spanish=nltk.FreqDist(list(nltk.trigrams(spanish_train)))\n",
    "print(fdist_trigram_spanish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1:  English vs. French unigram models, English vs. French bigram models,and English vs. French trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## English model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vs French unigram model\n",
      "English Unigram model accuracy with English test data=0.998\n"
     ]
    }
   ],
   "source": [
    "#English vs French unigram model\n",
    "print(\"English vs French unigram model\")\n",
    "count_eng = 0\n",
    "for i in english_test:\n",
    "  english_test_unigram =list(nltk.ngrams(i,1))\n",
    "  probability_english =1\n",
    "  probability_french  =1\n",
    "\n",
    "  for t in  english_test_unigram:\n",
    "     probability_english = probability_english * fdist_unigram_english.freq(t)\n",
    "     probability_french  = probability_french  *  fdist_unigram_french.freq(t)\n",
    "\n",
    "\n",
    "  if probability_english >= probability_french:\n",
    "         count_eng=count_eng+1   #smoothing\n",
    "\n",
    "print(\"English Unigram model accuracy with English test data=\" +str(count_eng/len(english_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vs French bigram model\n",
      "English Bigram model accuracy with English test data =1.0\n"
     ]
    }
   ],
   "source": [
    "#English vs French bigram model\n",
    "print(\"English vs French bigram model\")\n",
    "count_eng=0\n",
    "for i in english_test:\n",
    "  english_test_bigram =list(nltk.bigrams(i))\n",
    "  probability_english =1\n",
    "  probability_french  =1\n",
    "  for t in  english_test_bigram:\n",
    "     probability_english = probability_english * fdist_bigram_english.freq(t)\n",
    "     probability_french  = probability_french  *  fdist_bigram_french.freq(t)\n",
    "\n",
    "\n",
    "  if probability_english >= probability_french:\n",
    "         count_eng=count_eng+1  #smoothing\n",
    "        \n",
    "\n",
    "print(\"English Bigram model accuracy with English test data =\" +str(count_eng/len(english_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vs French trigram model\n",
      "English trigram model accuracy with English test data =1.0\n"
     ]
    }
   ],
   "source": [
    "#English vs French trigram model\n",
    "\n",
    "print(\"English vs French trigram model\")\n",
    "count_eng=0\n",
    "for i in english_test:\n",
    "  english_test_trigram =list(nltk.trigrams(i))\n",
    "  probability_english =1\n",
    "  probability_french  =1\n",
    "  for t in  english_test_trigram:\n",
    "     probability_english = probability_english * fdist_trigram_english.freq(t)\n",
    "     probability_french  = probability_french  *  fdist_trigram_french.freq(t)\n",
    "\n",
    "\n",
    "  if probability_english >= probability_french:\n",
    "         count_eng=count_eng+1\n",
    "\n",
    "print(\"English trigram model accuracy with English test data =\" +str(count_eng/len(english_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## French model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Unigram Accuracy with French test data \n",
      "French unigram model accuracy with French test data =0.992\n"
     ]
    }
   ],
   "source": [
    "# French vs english unigram model with french test data\n",
    "print(\"French Unigram Accuracy with French test data \")\n",
    "count_french = 0\n",
    "for i in french_test:\n",
    "    french_test_unigram = list(nltk.ngrams(i, 1))\n",
    "    probability_english = 1\n",
    "    probability_french = 1\n",
    "\n",
    "    for t in french_test_unigram:\n",
    "        probability_english = probability_english * fdist_unigram_english.freq(t)\n",
    "        probability_french = probability_french * fdist_unigram_french.freq(t)\n",
    "\n",
    "    if probability_english <= probability_french:\n",
    "        count_french = count_french + 1\n",
    "\n",
    "print(\"French unigram model accuracy with French test data =\" + str(count_french / len(french_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French bigram model Accuracy with French test data \n",
      "French bigram model accuracy with French test data =1.0\n"
     ]
    }
   ],
   "source": [
    "# French vs english bigram model with french test data\n",
    "print(\"French bigram model Accuracy with French test data \")\n",
    "count_french = 0\n",
    "for i in french_test:\n",
    "    french_test_bigram = list(nltk.bigrams(i))\n",
    "    probability_english = 1\n",
    "    probability_french = 1\n",
    "    for t in french_test_bigram:\n",
    "        probability_english = probability_english * fdist_bigram_english.freq(t)\n",
    "        probability_french = probability_french * fdist_bigram_french.freq(t)\n",
    "\n",
    "    if probability_english <= probability_french:\n",
    "        count_french = count_french + 1\n",
    "\n",
    "print(\"French bigram model accuracy with French test data =\" + str(count_french / len(french_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Trigram model Accuracy with French test data \n",
      "French trigram model accuracy with French test data =1.0\n"
     ]
    }
   ],
   "source": [
    "# French vs english trigram model with french test data\n",
    "print(\"French Trigram model Accuracy with French test data \")\n",
    "count_french = 0\n",
    "for i in french_test:\n",
    "    french_test_trigram = list(nltk.trigrams(i))\n",
    "    probability_english = 1\n",
    "    probability_french = 1\n",
    "    for t in french_test_trigram:\n",
    "        probability_english = probability_english * fdist_trigram_english.freq(t)\n",
    "        probability_french = probability_french * fdist_trigram_french.freq(t)\n",
    "\n",
    "    if probability_english <= probability_french:\n",
    "        count_french = count_french + 1\n",
    "\n",
    "print(\"French trigram model accuracy with French test data =\" + str(count_french / len(french_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 - Spanish vs Italian model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian Unigram model Accuracy with italian data \n",
      "Italian unigram model accuracy with italian data=1.0\n"
     ]
    }
   ],
   "source": [
    "# Italian vs spanish unigram model with italian test data\n",
    "print(\"Italian Unigram model Accuracy with italian data \")\n",
    "count_italian = 0\n",
    "for i in italian_test:\n",
    "    italian_test_unigram = list(nltk.ngrams(i, 1))\n",
    "    probability_italian = 1\n",
    "    probability_spanish = 1\n",
    "\n",
    "    for t in italian_test_unigram:\n",
    "        probability_italian = probability_italian * fdist_unigram_italian.freq(t)\n",
    "        probability_spanish = probability_spanish * fdist_unigram_spanish.freq(t)\n",
    "\n",
    "    if probability_italian >= probability_spanish:\n",
    "        count_italian = count_italian + 1\n",
    "\n",
    "print(\"Italian unigram model accuracy with italian data=\" + str(count_italian / len(italian_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian bigram Accuracy with italian test data\n",
      "Italian bigram model accuracy with italian data =1.0\n"
     ]
    }
   ],
   "source": [
    "# Italian vs spanish bigram model with italian test data\n",
    "print(\"Italian bigram Accuracy with italian test data\")\n",
    "count_italian = 0\n",
    "for i in italian_test:\n",
    "    italian_test_bigram = list(nltk.bigrams(i))\n",
    "    probability_italian = 1\n",
    "    probability_spanish = 1\n",
    "    for t in italian_test_bigram:\n",
    "        probability_italian = probability_italian * fdist_bigram_italian.freq(t)\n",
    "        probability_spanish = probability_spanish * fdist_bigram_spanish.freq(t)\n",
    "\n",
    "    if probability_italian >= probability_spanish:\n",
    "        count_italian = count_italian + 1\n",
    "\n",
    "print(\"Italian bigram model accuracy with italian data =\" + str(count_italian / len(italian_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian trigram Accuracy with italian test data\n",
      "Italian trigram model accuracy with italian test data=1.0\n"
     ]
    }
   ],
   "source": [
    "# Italian vs spanish trigram model with italian test data\n",
    "print(\"Italian trigram Accuracy with italian test data\")\n",
    "count_italian = 0\n",
    "for i in italian_test:\n",
    "    italian_test_trigram = list(nltk.trigrams(i))\n",
    "    probability_italian = 1\n",
    "    probability_spanish = 1\n",
    "    for t in italian_test_trigram:\n",
    "        probability_italian = probability_italian * fdist_trigram_italian.freq(t)\n",
    "        probability_spanish = probability_spanish * fdist_trigram_spanish.freq(t)\n",
    "\n",
    "    if probability_italian >= probability_spanish:\n",
    "        count_italian = count_italian + 1\n",
    "\n",
    "print(\"Italian trigram model accuracy with italian test data=\" + str(count_italian / len(italian_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spanish Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Unigram Accuracy with spanish test data\n",
      "Spanish unigram model accuracy with spanish test data=0.961\n"
     ]
    }
   ],
   "source": [
    "# Spanish vs italian unigram model with spanish test data\n",
    "print(\"Spanish Unigram Accuracy with spanish test data\")\n",
    "count_spanish = 0\n",
    "for i in spanish_test:\n",
    "    spanish_test_unigram = list(nltk.ngrams(i, 1))\n",
    "    probability_italian = 1\n",
    "    probability_spanish = 1\n",
    "\n",
    "    for t in spanish_test_unigram:\n",
    "        probability_italian = probability_italian * fdist_unigram_italian.freq(t)\n",
    "        probability_spanish = probability_spanish * fdist_unigram_spanish.freq(t)\n",
    "\n",
    "    if probability_italian <= probability_spanish:\n",
    "        count_spanish = count_spanish + 1\n",
    "\n",
    "print(\"Spanish unigram model accuracy with spanish test data=\" + str(count_spanish / len(spanish_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish bigram Accuracy  with spanish test data\n",
      "Spanish bigram model accuracy  with spanish test data=1.0\n"
     ]
    }
   ],
   "source": [
    "# Spanish vs italian bigram model with spanish test data\n",
    "print(\"Spanish bigram Accuracy  with spanish test data\")\n",
    "count_spanish = 0\n",
    "for i in spanish_test:\n",
    "    spanish_test_bigram = list(nltk.bigrams(i))\n",
    "    probability_italian = 1\n",
    "    probability_spanish = 1\n",
    "    for t in spanish_test_bigram:\n",
    "        probability_italian = probability_italian * fdist_bigram_italian.freq(t)\n",
    "        probability_spanish = probability_spanish * fdist_bigram_spanish.freq(t)\n",
    "\n",
    "    if probability_italian <= probability_spanish:\n",
    "        count_spanish = count_spanish + 1\n",
    "\n",
    "print(\"Spanish bigram model accuracy  with spanish test data=\" + str(count_spanish / len(spanish_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish trigram Accuracy with spanish test data\n",
      "Spanish trigram model accuracy with spanish test data=1.0\n"
     ]
    }
   ],
   "source": [
    "# Spanish vs italian trigram model with spanish test data\n",
    "print(\"spanish trigram Accuracy with spanish test data\")\n",
    "count_spanish = 0\n",
    "for i in spanish_test:\n",
    "    spanish_test_trigram = list(nltk.trigrams(i))\n",
    "    probability_italian = 1\n",
    "    probability_spanish = 1\n",
    "    for t in spanish_test_trigram:\n",
    "        probability_italian = probability_italian * fdist_trigram_italian.freq(t)\n",
    "        probability_spanish = probability_spanish * fdist_trigram_spanish.freq(t)\n",
    "\n",
    "    if probability_italian <= probability_spanish:\n",
    "        count_spanish = count_spanish + 1\n",
    "\n",
    "print(\"Spanish trigram model accuracy with spanish test data=\" + str(count_spanish / len(spanish_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish Vs Italian unigram model is harder to distinguish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
